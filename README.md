# Facebook Page Post Crawler

A robust Facebook page post crawler built with Python, Playwright, and MySQL. This system crawls Facebook pages, extracts posts with their metadata, and stores them in a database while avoiding detection.

## Features

- ğŸ¤– **Automated Crawling**: Uses Playwright to simulate real user behavior
- ğŸ”’ **Anti-Detection**: Implements stealth techniques to avoid Facebook checkpoints
- ğŸ’¾ **Database Storage**: Stores posts in MySQL with duplicate detection
- ğŸ“Š **Dashboard**: Streamlit-based interface to view and manage crawled data
- â° **Scheduled Tasks**: Celery-based periodic crawling
- ğŸ³ **Docker Support**: Fully containerized deployment

## Tech Stack

- **Python 3.11+**: Core programming language
- **Playwright**: Browser automation with stealth capabilities
- **BeautifulSoup4**: HTML parsing and data extraction
- **MySQL**: Database for structured data storage
- **Celery + Redis**: Task queue for scheduled crawling
- **Streamlit**: Web-based dashboard
- **Docker**: Containerization

## Installation

### Prerequisites

- Python 3.11 or higher
- MySQL 8.0+
- Redis 6.0+

### Setup

1. Clone the repository:
```bash
git clone https://github.com/tunnaduong/facebook-page-post-crawler.git
cd facebook-page-post-crawler
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
playwright install chromium
```

4. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

5. Initialize the database:
```bash
mysql -u root -p < database/schema.sql
```

## Usage

### Manual Crawling

Run a single crawl session:
```bash
python src/crawler.py --page "page_name"
```

### Scheduled Crawling

Start the Celery worker:
```bash
celery -A src.tasks worker --loglevel=info
```

Start the Celery beat scheduler:
```bash
celery -A src.tasks beat --loglevel=info
```

### Dashboard

Launch the Streamlit dashboard:
```bash
streamlit run src/dashboard.py
```

## Docker Deployment

Build and run with Docker Compose:
```bash
docker-compose up -d
```

This will start:
- MySQL database
- Redis server
- Celery worker
- Celery beat scheduler
- Streamlit dashboard

## Project Structure

```
facebook-page-post-crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler.py          # Main crawler logic
â”‚   â”œâ”€â”€ parser.py           # HTML parsing with BeautifulSoup
â”‚   â”œâ”€â”€ database.py         # Database operations
â”‚   â”œâ”€â”€ tasks.py            # Celery tasks
â”‚   â”œâ”€â”€ dashboard.py        # Streamlit dashboard
â”‚   â””â”€â”€ config.py           # Configuration management
â”œâ”€â”€ database/
â”‚   â””â”€â”€ schema.sql          # Database schema
â”œâ”€â”€ cookies/                # Stored browser cookies
â”œâ”€â”€ docker-compose.yml      # Docker orchestration
â”œâ”€â”€ Dockerfile              # Docker image definition
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Environment variables template
â””â”€â”€ README.md               # This file
```

## Anti-Detection Features

1. **Cookie Persistence**: Login once and reuse cookies
2. **User-Agent Spoofing**: Uses playwright-stealth to appear as a real browser
3. **Random Delays**: Natural timing between actions
4. **Scrolling Behavior**: Mimics human scrolling patterns
5. **Proxy Support**: Optional residential proxy integration

## Database Schema

The `fb_posts` table stores:
- `post_id`: Unique Facebook post identifier
- `page_name`: Name of the Facebook page
- `content`: Post text content
- `media_urls`: JSON array of image/video URLs
- `posted_at`: When the post was published
- `crawled_at`: When the post was crawled
- `engagement`: JSON object with likes, comments, shares

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is for educational purposes only. Please respect Facebook's Terms of Service and use responsibly.

## Disclaimer

This tool is intended for research and educational purposes. Users are responsible for complying with Facebook's Terms of Service and applicable laws. The authors are not responsible for misuse of this software.
